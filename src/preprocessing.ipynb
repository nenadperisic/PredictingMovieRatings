{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "44e4baef8aa2bfdee458aa519960f936f36d6c605b940cfa7e03f66b68608407"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval # using literal_eval we can make object from string\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import spacy\n",
    "import en_core_web_sm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# first database\n",
    "movie_genre = pd.read_csv(\"../data/movieGenres/MovieGenre.csv\", encoding=\"latin1\")\n",
    "# second database\n",
    "credits = pd.read_csv(\"../data/movies/credits.csv\", encoding=\"latin1\")\n",
    "keywords = pd.read_csv(\"../data/movies/keywords.csv\", encoding=\"latin1\")\n",
    "movies_metadata = pd.read_csv('../data/movies/movies_metadata.csv', encoding=\"latin1\")\n",
    "\n",
    "\n",
    "print(movie_genre.shape)\n",
    "print(credits.shape)\n",
    "print(keywords.shape)\n",
    "print(movies_metadata.shape)\n",
    "\n",
    "# movies_metadata.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(40108, 6)\n",
      "(45476, 3)\n",
      "(46419, 2)\n",
      "(45466, 24)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/shone/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3437: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# we need to rename column imdbId so it matches column name from movies_metadata.csv, for later join\n",
    "cleaned_movie_genre = movie_genre.rename(columns={'imdbId': 'imdb_id'})\n",
    "cleaned_movie_genre = cleaned_movie_genre.drop_duplicates(subset=['imdb_id'], keep=False)\n",
    "\n",
    "cleaned_credits = credits.drop_duplicates(subset=['id'], keep=False)\n",
    "cleaned_keywords = keywords.drop_duplicates(subset=['id'], keep=False)\n",
    "\n",
    "cleaned_movies_metadata = movies_metadata.copy()\n",
    "cleaned_movies_metadata = cleaned_movies_metadata[cleaned_movies_metadata['imdb_id']!='0']\n",
    "cleaned_movies_metadata['imdb_id'] = cleaned_movies_metadata['imdb_id'].str.replace('tt','')\n",
    "cleaned_movies_metadata['imdb_id'] = pd.to_numeric(cleaned_movies_metadata['imdb_id'], errors='coerce')\n",
    "cleaned_movies_metadata = cleaned_movies_metadata[~np.isnan(cleaned_movies_metadata['imdb_id'])]\n",
    "cleaned_movies_metadata['imdb_id'] = cleaned_movies_metadata['imdb_id'].astype(int)\n",
    "cleaned_movies_metadata = cleaned_movies_metadata.drop_duplicates(subset=['imdb_id'], keep=False)\n",
    "\n",
    "cleaned_movies_metadata['id'] = cleaned_movies_metadata['id'].astype(int)\n",
    "\n",
    "all_tables_merged = pd.merge(cleaned_movies_metadata, cleaned_credits, on='id')\n",
    "all_tables_merged = pd.merge(all_tables_merged, cleaned_keywords, on='id')\n",
    "all_tables_merged = pd.merge(all_tables_merged, cleaned_movie_genre, on='imdb_id')\n",
    "\n",
    "print(all_tables_merged.shape)\n",
    "\n",
    "all_tables_merged.to_csv('../data/preprocessed_data.csv', index=False)\n",
    "# all_tables_merged.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(37504, 32)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Removig columns that are not required"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# prepared_data = all_tables_merged.copy()\n",
    "prepared_data = pd.read_csv('../data/preprocessed_data.csv');\n",
    "prepared_data.drop('belongs_to_collection', 1, inplace=True)\n",
    "prepared_data.drop('homepage', 1, inplace=True)\n",
    "prepared_data.drop('poster_path', 1, inplace=True)\n",
    "prepared_data.drop('video', 1, inplace=True)\n",
    "prepared_data.drop('Poster', 1, inplace=True)\n",
    "prepared_data.drop('original_title', 1, inplace=True)\n",
    "prepared_data.drop('Title', 1, inplace=True)\n",
    "print(prepared_data.shape)\n",
    "# data_preparation.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will filter english movies that are released after 1970."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "prepared_data = prepared_data[prepared_data.original_language == 'en']\n",
    "pd.to_datetime(prepared_data.release_date)\n",
    "prepared_data['year'] = pd.DatetimeIndex(prepared_data['release_date']).year\n",
    "prepared_data = prepared_data.loc[prepared_data.year > 1970]\n",
    "print(prepared_data.shape)\n",
    "\n",
    "prepared_data.to_csv('../data/preprocessed_data_2.csv', index=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(21567, 26)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# We will extract top 2 actors, top 2 comapanies, and director"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def get_director(crew):\n",
    "    for director in crew:\n",
    "        if director['job'] == 'Director':\n",
    "            return director['name']\n",
    "    return\n",
    "\n",
    "def get_actors(cast):\n",
    "    if isinstance(cast, list):\n",
    "        actors = [actor['name'] for actor in cast]\n",
    "        if len(actors) >= 2:\n",
    "            actors = actors[:2]\n",
    "            return '|'.join(actors)\n",
    "        return '|'.join(actors)\n",
    "\n",
    "def get_production_companies(companies):\n",
    "    if isinstance(companies, list):\n",
    "        prod_companies = [company['name'] for company in companies]\n",
    "        if len(prod_companies) >= 2:\n",
    "            prod_companies = prod_companies[:2]\n",
    "            return '|'.join(prod_companies)\n",
    "        elif prod_companies == 0:\n",
    "            return ''\n",
    "        return '|'.join(prod_companies)\n",
    "\n",
    "\n",
    "prepared_data.dropna(subset=['production_companies'], inplace=True)\n",
    "directors = prepared_data['crew'].apply(literal_eval).apply(get_director)\n",
    "top_2_actors = prepared_data['cast'].apply(literal_eval).apply(get_actors)\n",
    "top_2_companies = prepared_data['production_companies'].apply(literal_eval).apply(get_production_companies)\n",
    "\n",
    "# print(directors)\n",
    "# print(top_2_actors)\n",
    "# print(top_2_companies)\n",
    "prepared_data['director'] = directors\n",
    "prepared_data['actors'] = top_2_actors\n",
    "prepared_data['companies'] = top_2_companies\n",
    "prepared_data.to_csv('../data/preprocessed_data_3.csv', index=False)\n",
    "# prepared_data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "included_columns = ['IMDB Score', 'overview', 'Genre', 'actors', 'runtime', 'director', 'budget', 'companies']\n",
    "preprocessed_data_3 = pd.read_csv('../data/preprocessed_data_3.csv')\n",
    "data_to_use = preprocessed_data_3[included_columns]\n",
    "print(data_to_use.shape)\n",
    "data_to_use = data_to_use.dropna()\n",
    "print(data_to_use.shape)\n",
    "data_to_use.head()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(21567, 8)\n",
      "(15041, 8)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   IMDB Score                                           overview  \\\n",
       "0         8.3  Led by Woody, Andy's toys live happily in his ...   \n",
       "1         6.9  When siblings Judy and Peter discover an encha...   \n",
       "2         6.6  A family wedding reignites the ancient feud be...   \n",
       "3         5.7  Cheated on, mistreated and stepped on, the wom...   \n",
       "4         5.9  Just when George Banks has recovered from his ...   \n",
       "\n",
       "                        Genre                          actors  runtime  \\\n",
       "0  Animation|Adventure|Comedy             Tom Hanks|Tim Allen     81.0   \n",
       "1     Action|Adventure|Family    Robin Williams|Jonathan Hyde    104.0   \n",
       "2              Comedy|Romance      Walter Matthau|Jack Lemmon    101.0   \n",
       "3        Comedy|Drama|Romance  Whitney Houston|Angela Bassett    127.0   \n",
       "4       Comedy|Family|Romance       Steve Martin|Diane Keaton    106.0   \n",
       "\n",
       "          director    budget                                  companies  \n",
       "0    John Lasseter  30000000                    Pixar Animation Studios  \n",
       "1     Joe Johnston  65000000              TriStar Pictures|Teitler Film  \n",
       "2    Howard Deutch         0                Warner Bros.|Lancaster Gate  \n",
       "3  Forest Whitaker  16000000     Twentieth Century Fox Film Corporation  \n",
       "4    Charles Shyer         0  Sandollar Productions|Touchstone Pictures  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMDB Score</th>\n",
       "      <th>overview</th>\n",
       "      <th>Genre</th>\n",
       "      <th>actors</th>\n",
       "      <th>runtime</th>\n",
       "      <th>director</th>\n",
       "      <th>budget</th>\n",
       "      <th>companies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>Animation|Adventure|Comedy</td>\n",
       "      <td>Tom Hanks|Tim Allen</td>\n",
       "      <td>81.0</td>\n",
       "      <td>John Lasseter</td>\n",
       "      <td>30000000</td>\n",
       "      <td>Pixar Animation Studios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.9</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>Action|Adventure|Family</td>\n",
       "      <td>Robin Williams|Jonathan Hyde</td>\n",
       "      <td>104.0</td>\n",
       "      <td>Joe Johnston</td>\n",
       "      <td>65000000</td>\n",
       "      <td>TriStar Pictures|Teitler Film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.6</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>Walter Matthau|Jack Lemmon</td>\n",
       "      <td>101.0</td>\n",
       "      <td>Howard Deutch</td>\n",
       "      <td>0</td>\n",
       "      <td>Warner Bros.|Lancaster Gate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.7</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>Whitney Houston|Angela Bassett</td>\n",
       "      <td>127.0</td>\n",
       "      <td>Forest Whitaker</td>\n",
       "      <td>16000000</td>\n",
       "      <td>Twentieth Century Fox Film Corporation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.9</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>Comedy|Family|Romance</td>\n",
       "      <td>Steve Martin|Diane Keaton</td>\n",
       "      <td>106.0</td>\n",
       "      <td>Charles Shyer</td>\n",
       "      <td>0</td>\n",
       "      <td>Sandollar Productions|Touchstone Pictures</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def get_words(message, tokenizer = None):\n",
    "    if tokenizer:\n",
    "        doc = tokenizer(message)\n",
    "        return [i.text for i in doc]\n",
    "    else:\n",
    "        return message.lower().split('|')\n",
    "\n",
    "def create_dictionary(messages, min_count = 5, tokenizer = None):\n",
    "    words_count = {}\n",
    "    for s in messages:\n",
    "        words = get_words(s, tokenizer)\n",
    "        words_unique = list(dict.fromkeys(words))\n",
    "        for w in words_unique:\n",
    "            if w not in words_count:\n",
    "                words_count[w] = 1\n",
    "            else:\n",
    "                words_count[w] += 1\n",
    "\n",
    "    for word in list(words_count.keys()):\n",
    "        if words_count[word] < min_count:\n",
    "            del words_count[word]\n",
    "\n",
    "    index = 1\n",
    "    for word in list(words_count.keys()):\n",
    "        words_count[word] = index\n",
    "        index = index + 1\n",
    "\n",
    "    return words_count\n",
    "\n",
    "\n",
    "def transform_text(messages, word_dictionary, tokenizer = None):\n",
    "    words_arr = np.zeros((len(messages), len(word_dictionary)))\n",
    "    for i in range(words_arr.shape[0]):\n",
    "        message_words = get_words(messages[i], tokenizer)\n",
    "        message_indices = map(word_dictionary.get, message_words)\n",
    "        for j in message_indices:\n",
    "            if j is not None:\n",
    "                words_arr[i, j-1] += 1\n",
    "    return words_arr\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split into train, validation and test set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "train_dataset, test_dataset = train_test_split(data_to_use, test_size=0.3, random_state = 0)\n",
    "# valid_dataset, test_dataset = train_test_split(test_dataset, test_size=0.5, random_state = 0)\n",
    "\n",
    "train_data = train_dataset.reset_index(drop=True)\n",
    "# valid_data = valid_dataset.reset_index(drop=True)\n",
    "test_data = test_dataset.reset_index(drop=True)\n",
    "\n",
    "print(train_data.shape)\n",
    "# print(valid_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "train_data.to_csv('../data/train.csv', index = False)\n",
    "# valid_data.to_csv('../data/valid.csv', index = False)\n",
    "test_data.to_csv('../data/test.csv', index = False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(10528, 8)\n",
      "(4513, 8)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can take this data and do binarization and then we will apply regression algorithms"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_data = pd.read_csv('../data/train.csv')\n",
    "test_data = pd.read_csv('../data/test.csv')\n",
    "\n",
    "genre_dictionary = create_dictionary(train_data['Genre'].astype(str).values, min_count=5)\n",
    "train_genre_matrix = transform_text(train_data['Genre'].astype(str).values, genre_dictionary)\n",
    "test_genre_matrix = transform_text(test_data['Genre'].astype(str).values, genre_dictionary)\n",
    "# valid_genre_matrix = transform_text(valid_data['Genre'].astype(str).values, genre_dictionary)\n",
    "\n",
    "director_dictionary = create_dictionary(train_data['director'].astype(str).values, min_count=5)\n",
    "train_director_matrix = transform_text(train_data['director'].astype(str).values, director_dictionary)\n",
    "test_director_matrix = transform_text(test_data['director'].astype(str).values, director_dictionary)\n",
    "# valid_director_matrix = transform_text(valid_data['director'].astype(str).values, director_dictionary)\n",
    "\n",
    "actors_dictionary = create_dictionary(train_data['actors'].astype(str).values, min_count = 5)\n",
    "train_actors_matrix = transform_text(train_data['actors'].astype(str).values, actors_dictionary)\n",
    "test_actors_matrix = transform_text(test_data['actors'].astype(str).values, actors_dictionary)\n",
    "# valid_actors_matrix = transform_text(valid_data['actors'].astype(str).values, actors_dictionary)\n",
    "\n",
    "companies_dictionary = create_dictionary(train_data['companies'].astype(str).values, min_count=5)\n",
    "train_companies_matrix = transform_text(train_data['companies'].astype(str).values, companies_dictionary)\n",
    "test_companies_matrix = transform_text(test_data['companies'].astype(str).values, companies_dictionary)\n",
    "# valid_companies_matrix = transform_text(valid_data['companies'].astype(str).values, companies_dictionary)\n",
    "\n",
    "tokenizer = en_core_web_sm.load(disable=[\"tagger\", \"parser\",\"ner\"])\n",
    "overview_dictionary = create_dictionary(train_data['overview'], min_count = 20, tokenizer=tokenizer)\n",
    "print('Size of dictionary: ', len(overview_dictionary))\n",
    "train_overview_matrix = transform_text(train_data['overview'].astype(str).values, overview_dictionary)\n",
    "test_overview_matrix = transform_text(test_data['overview'].astype(str).values, overview_dictionary)\n",
    "# valid_overview_matrix = transform_text(valid_data['overview'].astype(str).values, overview_dictionary)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "train_data = pd.concat([train_data, pd.DataFrame(train_genre_matrix, columns = genre_dictionary.keys()), \n",
    "                                    pd.DataFrame(train_director_matrix, columns=director_dictionary.keys()), \n",
    "                                    pd.DataFrame(train_actors_matrix, columns = actors_dictionary.keys()),\n",
    "                                    pd.DataFrame(train_companies_matrix, columns = companies_dictionary.keys()),\n",
    "                                    pd.DataFrame(train_overview_matrix, columns = overview_dictionary.keys())], axis=1)\n",
    "\n",
    "train_data.to_csv('../data/train_final.csv', index = False)\n",
    "# train_data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# valid_data = pd.concat([valid_data, pd.DataFrame(valid_genre_matrix, columns = genre_dictionary.keys()), \n",
    "#                                     pd.DataFrame(valid_director_matrix, columns=director_dictionary.keys()), \n",
    "#                                     pd.DataFrame(valid_actors_matrix, columns = actors_dictionary.keys()),\n",
    "#                                     pd.DataFrame(valid_companies_matrix, columns = companies_dictionary.keys()),\n",
    "#                                     pd.DataFrame(valid_overview_matrix, columns = overview_dictionary.keys())], axis=1)\n",
    "\n",
    "# valid_data.to_csv('../data/valid_final.csv', index = False)\n",
    "# # valid_data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "test_data = pd.concat([test_data,   pd.DataFrame(test_genre_matrix, columns = genre_dictionary.keys()), \n",
    "                                    pd.DataFrame(test_director_matrix, columns=director_dictionary.keys()), \n",
    "                                    pd.DataFrame(test_actors_matrix, columns = actors_dictionary.keys()),\n",
    "                                    pd.DataFrame(test_companies_matrix, columns = companies_dictionary.keys()),\n",
    "                                    pd.DataFrame(test_overview_matrix, columns = overview_dictionary.keys())], axis=1)\n",
    "\n",
    "test_data.to_csv('../data/test_final.csv', index = False)\n",
    "# test_data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# import sys\n",
    "\n",
    "# orig_stdout = sys.stdout\n",
    "# f = open('columns.txt', 'w')\n",
    "# sys.stdout = f\n",
    "\n",
    "# for col in train_data.columns:\n",
    "#     print(col)\n",
    "\n",
    "# sys.stdout = orig_stdout\n",
    "# f.close()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}